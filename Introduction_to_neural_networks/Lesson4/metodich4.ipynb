{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nbePKeGEYbaT"
   },
   "source": [
    "# Введение в искусственные нейронные сети\n",
    "# Урок 5. Сверточные нейронные сети"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-d0oOtp5Ybah"
   },
   "source": [
    "## Содержание методического пособия:\n",
    "\n",
    "\n",
    "<ol>\n",
    "<li>Что такое Сверточные нейронные сети</li>\n",
    "<li>Архитектура Сверточных нейронных сетей</li>\n",
    "<li>Несколько практических примеров сверточных нейронных сетей на Keras</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GVDchEuFYbai"
   },
   "source": [
    "## Что такое Сверточные нейронные сети\n",
    "\n",
    "Сверточные нейронные сети - это нейронные сети приспособленные впервую очередь для задач распознования образов. В их основе лежат работы в области изучения зрительной коры головного мозга. Их отличительная черта - добавление сверточных и пуллинговых слоев в архитектуру нейронной сети. Подробности архитектуры мы рассмотрим в следующей части данного методического пособия, а пока давайте взглянем на области применения данного вида нейронных сетей:\n",
    "\n",
    "- Задачи связанные с определением того какому классу принадлежит объект на фотографии\n",
    "\n",
    "- Сверточные нейронные сети в модифицированном виде могут определять не только что находиться на фотографии, но где находиться (этому виду нейронных сетей будет посвящен отдельный урок)\n",
    "\n",
    "- Распознование лиц. В 2001 г. появился алгоритм Виолы-Джонса, который предложил технологию позволяющую технике находить лица на фотографиях и  в видеопотоке. На данный момент по эфективности этот алгоритм превзайден свертончными нейронными сетями.\n",
    "\n",
    "- Проставление лейблов изображениям. Используется Google, Amazon, Facebook\n",
    "\n",
    "- Визуальный поиск. Используется Google\n",
    "\n",
    "- Рекомендательные системы. Amazon например, использует это для секции \"вам также может понравиться\" для одежды.\n",
    "\n",
    "- В социальных сетях, с помощью них отмечаются люди на фотографиях\n",
    "\n",
    "- Помощь врачам в анализе медицинских снимков\n",
    "\n",
    "- Предиктивная аналитика. Помощь в предсказании проблем со здоровьем\n",
    "\n",
    "- Оценка цифр написанных от руки банками. Одно из самых ранних применений сверточных нейронных сетей.\n",
    "\n",
    "Однако применение сверточных нейронных сетей не ограничивается областью компьютерного зрения. Они также применяются и в других областях:\n",
    "\n",
    "- Анализ текстов. Для этого больше подходят рекуррентные нейронные сети, но когда речь заходит о детекции определенных признаков в тексте например бранной речи, лучше могут подойти сверточные нейронные сети\n",
    "\n",
    "- Предиктивный анализ. В частности предсказание погоды.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0OvDRC1MYbal"
   },
   "source": [
    "## Глубокое обучение\n",
    "\n",
    "![full_connected.png](attachment:full_connected.png)\n",
    "\n",
    "Источник изображения - https://camo.githubusercontent.com/920e95dc71acebe014549c9288cbf42cbe5c8afc/68747470733a2f2f6861726973686e61726179616e616e2e6f72672f696d616765732f77726974696e672f61727469737469632d7374796c652d7472616e736665722f726570726573656e746174696f6e2d6c6561726e696e672e706e67\n",
    "\n",
    "\n",
    "\n",
    "Глубокое обучение - это обучение глубоких нейронных сетей. Глубокие нейронные сети - это сети с больше чем одним внутренним слоем.\n",
    "\n",
    "Однако, прежде чем мы начнем разбирать глубокое обучение давайте в кратце опишем сверточные нейронные сети. Типичная сверточная нейронная сеть состоит из входного слоя и череды сверточных и пуллинговых слоев, следующих как правило друг за другом и нескольких полносвязных слоев на выходе.\n",
    "\n",
    "Давайте попробуем разобраться в смысле данной архитектуры и как она связана с глубоким обучением. В отношение нейронных сетей известно, что нейронная сеть в один слой может лишить любую задачу. Но такой подход будет очень грубым решением проблемы и вычислительной мощности современных компьютеров не хватит, чтобы нейронная сеть в один слой например могла различать классы объектов на фотографии. \n",
    "\n",
    "Данная диллема решается через другой научный факт известный в отношении нейронных сетей - чем больше слоев тем эффективнее нейросеть. Т.е. строя многослойную нейронную сеть может понадобиться меньше нейронов чем если строить однослойную. Связано это с тем, что каждый слой выучивает признаки на определенном уровне абстракции и следующии за ним слои используют уже имеющиеся признаки, а не выучивают их заново.\n",
    "\n",
    "Давайте в общих чертах посмотрим на то, как происходит процесс обучение в глубокой нейронной сети, поскольку такой же процесс в общих чертах будет характерен и для сверточных нейронных сетей.\n",
    "\n",
    "Допустим мы будем работать с изображениями животных. Первые слои выучат признаки животных низкого уровня абстракции такие как линии под определенными углами, следующие слои на базе этих признаков выучат более сложные признаки, например геом. фигуры на базе сочетания этих линий. Следующие слои выучат такие признаки как глаза, уши и т.д. которые будут составлены из этих геометрических фигур. Подобные высокоасбтрактные признаки как названнные выше уже можно использовать для того чтобы сделать заключение какое животное на картинке.\n",
    "\n",
    "Описанная система лучше с точки зрения вычислительных затрат. Однако если мы сделаем несколько полносвязных слоев где каждый нейрон связан с каждым нейроном другого слоя, то на обсчитывание этих связей уйдет меньше вычисл. ресурсов чем если бы нейронная сеть была в один слой, но всеравно такая нейронная сеть в не учебных задачах будет обучаться неприемлимо долго. \n",
    "\n",
    "\n",
    "## Архитектура Сверточных нейронных сетей\n",
    "\n",
    "![lenet.png](attachment:lenet.png)\n",
    "Источник - http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf\n",
    "\n",
    "Сверточные нейронные сети - это самый природо-подобный алгоритм из всех. Современные сверточные нейронные сети базируется на произведшей революцию в комп. зрении нейронной сети AlexNet, она базируется на сверточных нейронных сетях, которые разрабатывал Ян Лекун в 90 гг., те в свою очередь базируется на японском Neocognitron 1980 г., а он свою очередь на открытиях в области зрительной коры головного мозга. Конечно современные архитектуры сверточных нейронных сетей такие Inception-v4 сильно отличаются от сверточных нейронных сетей 90-x. Однако у них есть общие черты, которые и делают сверточные нейронные сети эффективными. Особенности сверточных нейронных сетей о которых речь пойдет далее призваны помочь строить глубокие нейронные сети, имеющими меньшие вычислительные затраты чем полносвязные. \n",
    "\n",
    "Главная отличительная черта сверточных нейронных сетей - это наличие сверточных слоев и пуллинг слоев. Подобные слои как раз и были обнаружены в зрительной коре головного мозга, но они называны по другому и работают конечно более сложным образом. В искусственной нейронной сети сверточный слой состоит из фрагментов, которые связаны только с определенной частью изображения, что позволяет не связывать каждый нейрон с каждым пикселем и уменьшить вычислительные затраты. Конечная цель сверточного слоя получить определенные признаки от изображения и передать их в следующий слой, точно также как и случае с обычной полнозсвязной нейронной сетью. Но сверточный слой это делает более эффективно. Если говорить упрощенно, то сама операция свертки предствляет из себя процесс преобразования большего набора чисел в меньший набор чисел их репрезентующий. Пуллинг слои следуют за сверточными слоями и призваны очистить от лишней информации эти признаки и убрать у них локальную привязку. Сама операция пуллинга если говорить опять же упрощенно представляет из себя процесс отбрасывания менее значимых сигналов представленных в виде чисел. Пулинг слои являются важной состовляющей нейронных сетей, однако из-за них сверточной нейронной сети всеравно где располагаются глаза например у кота над носом или под носом, главное сочетание этих признаков.\n",
    "\n",
    "Сверточная нейронная сеть строиться по принципу пирамиды - первые слои содержат больше нейронов, а последующие все меньше и меньше. Связано это с тем что низкоабстрактных признаков больше чем высокоабстрактных.\n",
    "\n",
    "Как правило на конце нейронной сети располагаются несколько полносвязных слоев. Эти слои как раз уже учатся на высокоабстрактных признаках которых немного и соотвественно не требуется много слоев и соотвесвенно с точки зрения вычислительных затрат они приемлимы. Т.е. получается сверточную нейронную сеть можно условно поделить на две части - одна извлекается признаки, а другая, полносвязная обучается на этих признаках.\n",
    "\n",
    "Однако стоит отметить, что современные сверточные нейронные сети в целях оптимизации их работы снабжаются многим дополнительными архитектурными решениями, такими например как возможность иметь в одном слое разные конфигурации свертки, пропускать при необходимости сигнал обратного распространения ошибки сквозь слои, использование нескольких слоев свертки подряд, неиспользование полносвязных слоев на конце нейронных сетей. Как правило, все эти нововведения направлены на то чтобы сделать нейронные сети более глубокими, что в свою очередь улучшает точность работы нейронных сетей. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EzyGSqxdYbar"
   },
   "source": [
    "## Пример создания сверточных и пуллинг слоев на Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Kn9W5zXNYbas",
    "outputId": "8b525fb7-92f6-4859-d611-1cdc396a3370"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_4 (Conv2D)           (None, 6, 6, 1)           10        \n",
      "                                                                 \n",
      " global_max_pooling2d (Globa  (None, 1)                0         \n",
      " lMaxPooling2D)                                                  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10\n",
      "Trainable params: 10\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "[[3.]]\n"
     ]
    }
   ],
   "source": [
    "from numpy import asarray\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import GlobalMaxPooling2D\n",
    "\n",
    "# определение входных данных(8 массивов с 8 элементами)\n",
    "data = [[0, 0, 0, 1, 1, 0, 0, 0],\n",
    "\t\t[0, 0, 0, 1, 1, 0, 0, 0],\n",
    "\t\t[0, 0, 0, 1, 1, 0, 0, 0],\n",
    "\t\t[0, 0, 0, 1, 1, 0, 0, 0],\n",
    "\t\t[0, 0, 0, 1, 1, 0, 0, 0],\n",
    "\t\t[0, 0, 0, 1, 1, 0, 0, 0],\n",
    "\t\t[0, 0, 0, 1, 1, 0, 0, 0],\n",
    "\t\t[0, 0, 0, 1, 1, 0, 0, 0]]\n",
    "\n",
    "data = asarray(data)\n",
    "data = data.reshape(1, 8, 8, 1)\n",
    "\n",
    "# создание модели\n",
    "model = Sequential()\n",
    "model.add(Conv2D(1, (3,3), activation='relu', input_shape=(8, 8, 1)))\n",
    "model.add(GlobalMaxPooling2D())\n",
    "\n",
    "# вывод описания созданной модели\n",
    "model.summary()\n",
    "\n",
    "# определение дектора вертикальной линии\n",
    "detector = [[[[0]],[[1]],[[0]]],\n",
    "            [[[0]],[[1]],[[0]]],\n",
    "            [[[0]],[[1]],[[0]]]]\n",
    "weights = [asarray(detector), asarray([0.0])]\n",
    "\n",
    "# сохранение весов в модель\n",
    "model.set_weights(weights)\n",
    "\n",
    "# применение фильтра к входным данным\n",
    "yhat = model.predict(data)\n",
    "\n",
    "print(yhat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l0B78jVjYba0"
   },
   "source": [
    "## Нейронная сеть Lenet5.\n",
    "\n",
    "Lenet5 - это одна из первых сверточных нейронных сетей и она отражает характерные для сверточных нейронных сетей набор элементов - сверточные слои, пуллинг слои и полносвязные слои на конце нейронной сети. Данная архитектура послужила основой для многих современных архитектур сверточных нейронных сетей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EwMJXcRsYba1",
    "outputId": "9e1a908f-2d1e-4317-c89a-a30a88e62708"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 1s 0us/step\n",
      "469/469 [==============================] - 64s 135ms/step - loss: 0.6152 - accuracy: 0.8448 - val_loss: 0.3347 - val_accuracy: 0.9057\n",
      "313/313 [==============================] - 5s 14ms/step - loss: 0.3347 - accuracy: 0.9057\n",
      "Test loss 0.3347, accuracy 90.57%\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "\n",
    "# загрузка тренировочных и тестовых данных\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# конвертация чисел из uint8 в float32\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "# нормализация данных [0, 1]\n",
    "x_train /= 255 \n",
    "x_test /= 255 \n",
    "\n",
    "# трансформация лейблов в one-hot encoding\n",
    "y_train = np_utils.to_categorical(y_train, 10) \n",
    "y_test = np_utils.to_categorical(y_test, 10) \n",
    "\n",
    "# изменение размерности массива в 4D массив\n",
    "x_train = x_train.reshape(x_train.shape[0], 28,28,1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28,28,1)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras import models, layers\n",
    "import keras\n",
    "\n",
    "# инициализация пустой модели\n",
    "model = Sequential()\n",
    "\n",
    "# первый сверточный слой\n",
    "model.add(layers.Conv2D(6, kernel_size=(5, 5), strides=(1, 1), activation='tanh', input_shape=(28,28,1), padding=\"same\"))\n",
    "\n",
    "# второй пуллинговый слой\n",
    "model.add(layers.AveragePooling2D(pool_size=(2, 2), strides=(1, 1), padding='valid'))\n",
    "\n",
    "# третий сверточный слой\n",
    "model.add(layers.Conv2D(16, kernel_size=(5, 5), strides=(1, 1), activation='tanh', padding='valid'))\n",
    "\n",
    "# четвертый пуллинговый слой\n",
    "model.add(layers.AveragePooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid'))\n",
    "\n",
    "# пятый полносвязный слой\n",
    "model.add(layers.Conv2D(120, kernel_size=(5, 5), strides=(1, 1), activation='tanh', padding='valid'))\n",
    "\n",
    "# сглаживание CNN выхода чтобы можно было его присоединить к полносвязногому слою\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "# шестой полносвязный слой\n",
    "model.add(layers.Dense(84, activation='tanh'))\n",
    "\n",
    "# выходной слой с функцией активации softmax\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "\n",
    "# компилияция модели\n",
    "model.compile(loss=keras.losses.categorical_crossentropy, optimizer='SGD', metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "hist = model.fit(x=x_train,y=y_train, epochs=1, batch_size=128, validation_data=(x_test, y_test), verbose=1)\n",
    "\n",
    "test_score = model.evaluate(x_test, y_test)\n",
    "print(\"Test loss {:.4f}, accuracy {:.2f}%\".format(test_score[0], test_score[1] * 100))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tTF-FxNLYba3"
   },
   "source": [
    "## Пример на Keras более сложной сверточной нейронной сети"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UEM1tcHpYba4"
   },
   "source": [
    "Давайте теперь попробуем сделать несколько усложненный вариант нейронной сети разобранной ранее. В ней будет на несколько слоев больше и в ней будет использоваться data augumentation, процедура позволяющая за счет искажений изображений увеличить количество тренировочных данных, а как мы знаем чем больше тренировочных данных тем лучше будет работать нейросеть. Для обучения нейросети будем использовать датасет cifar-10. В нем 10 категорий объектов, например - лошадь, лягушка, корабль. Данный датасет уже более сложен для нейронных сетей чем mnist, однако он намного проще датасетов наподобие imagenet где используются сотни классов и архитектуры нейронных сетей для подобных датасетов также понадобяться более сложные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_pdo_e68Yba5",
    "outputId": "7bbbe3af-5cfb-4c1a-c294-75d115f5749d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170498071/170498071 [==============================] - 6s 0us/step\n",
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 тренировочные примеры\n",
      "10000 тестовые примеры\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/rmsprop.py:135: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(RMSprop, self).__init__(name, **kwargs)\n",
      "<ipython-input-1-9abb8282a8aa>:105: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(datagen.flow(x_train, y_train,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Использование data augmentation в реальном времени\n",
      "1563/1563 [==============================] - 182s 116ms/step - loss: 1.9057 - accuracy: 0.3004 - val_loss: 1.6039 - val_accuracy: 0.4224\n",
      "сохранить обученную модель как /content/saved_models/keras_cifar10_trained_model.h5 \n",
      "313/313 [==============================] - 9s 29ms/step - loss: 1.6039 - accuracy: 0.4224\n",
      "Test loss: 1.603925108909607\n",
      "Test accuracy: 0.42239999771118164\n"
     ]
    }
   ],
   "source": [
    " from __future__ import print_function\n",
    "import keras # расскоментируйте эту строку, чтобы начать обучение\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import os\n",
    "\n",
    "# установка параметров нейросети\n",
    "batch_size = 32\n",
    "num_classes = 10\n",
    "epochs = 1\n",
    "data_augmentation = True\n",
    "num_predictions = 20\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'keras_cifar10_trained_model.h5'\n",
    "\n",
    "# разделение тренировочной и тестовой выборки\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'тренировочные примеры')\n",
    "print(x_test.shape[0], 'тестовые примеры')\n",
    "\n",
    "# преобразование матрицы чисел 0-9 в бинарную матрицу чисел 0-1\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "# конфигурирование слоев нейросети\n",
    "model = Sequential()\n",
    "\n",
    "# слои нейросети отвественные за свертку и max-pooling\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# полносвязные слои нейронной сети\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# инициализация RMSprop optimizer\n",
    "opt = keras.optimizers.RMSprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "# компиляция модели\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "if not data_augmentation:\n",
    "    print('Не используется data augmentation')\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)\n",
    "else:\n",
    "    print('Использование data augmentation в реальном времени')\n",
    "    # Препроцессинг и data augmentation в реальном времени:\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,\n",
    "        samplewise_center=False,\n",
    "        featurewise_std_normalization=False,\n",
    "        samplewise_std_normalization=False,\n",
    "        zca_whitening=False, \n",
    "        zca_epsilon=1e-06, \n",
    "        rotation_range=0, \n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0., \n",
    "        zoom_range=0., \n",
    "        channel_shift_range=0.,\n",
    "        fill_mode='nearest',\n",
    "        cval=0.,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=False,\n",
    "        rescale=None,\n",
    "        preprocessing_function=None,\n",
    "        data_format=None,\n",
    "        validation_split=0.0)\n",
    "\n",
    "    # запуск data augmentation через fit\n",
    "    #datagen.fit(x_train)\n",
    "\n",
    "    # запуск data augmentation через fit_generator\n",
    "    model.fit_generator(datagen.flow(x_train, y_train,\n",
    "                                     batch_size=batch_size),\n",
    "                        epochs=epochs,\n",
    "                        validation_data=(x_test, y_test),\n",
    "                        workers=4)\n",
    "\n",
    "# сохранение модели и весов\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "print('сохранить обученную модель как %s ' % model_path)\n",
    "\n",
    "# проверка работы обученной модели\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E5FhyuAYYba8"
   },
   "source": [
    "## Практическое задание\n",
    "\n",
    "<ol>\n",
    "    <li>Попробовать улучшить точность распознования образов cifar 10 сверточной нейронной сетью, рассмотренной на уроке. Приложить анализ с описанием того, что улучшает работу нейронной сети и что ухудшает.\n",
    "    </li>\n",
    "    <li>Описать также в анализе какие необоходимо внести изменения  в получившуюся у вас нейронную сеть если бы ей нужно было работать не с cifar10, а с MNIST, CIFAR100 и IMAGENET.\n",
    "    </li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TtCpRSWiYba_"
   },
   "source": [
    "## Дополнительные материалы\n",
    "\n",
    "<ol>\n",
    "    <li>https://keras.io/layers/convolutional/</li>\n",
    "    <li>https://keras.io/layers/pooling/</li>\n",
    "    <li>https://keras.io/preprocessing/image/</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "brC-9Bu_YbbA"
   },
   "source": [
    "## Используемая литература \n",
    "\n",
    "Для подготовки данного методического пособия были использованы следующие ресурсы:\n",
    "<ol>\n",
    "    <li>https://keras.io</li>\n",
    "    <li>Шакла Н. — Машинное обучение и TensorFlow 2019</li>\n",
    "    <li>Николенко Сергей Игоревич, Кадурин А. А. - Глубокое обучение. Погружение в мир нейронных сетей  2018</li>\n",
    "    <li>Francois Chollet - Deep Learning with Python 2018</li>\n",
    "    <li>Alex Krizhevsky, Ilya Sutskever, Geoffrey E. Hinton - ImageNet Classification with Deep Convolutional Neural Networks</li>\n",
    "    <li>Karen Simonyan, Andrew Zisserman - Very Deep Convolutional Networks for Large-Scale Image Recognition</li>\n",
    "    <li>Википедия</li>    \n",
    "</ol>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
